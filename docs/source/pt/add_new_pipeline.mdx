
<!--Copyright 2020 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
-->

# Como adicionar uma Pipeline  ü§ó Transformers?

Primeiramente, √© preciso definir as entradas sem tratamento que a pipeline poder√° receber. Essa poder√° ser strings, raw bytes, dicion√°rios ou qualquer coisa que seja a entrada desejada. 
Tente manter o mais pr√≥ximo do Python puro poss√≠vel, j√° que isso facilita torna a compatibilidade mais f√°cil (at√© mesmo com outras linguages atrav√©s do JSON). 
A entrada espec√≠ficada ser√° utilizada como `inputs`  na sess√£o `preprocess` da pipeline.

Ap√≥s isso, defina os `outputs`. Esses seguem a mesma regra dos `inputs` mencionados antes. Quanto mais simples, melhor. Esses ser√£o os retornos do m√©todo `postprocess`.

Comece herdando a classe base `Pipeline` junto dos  4 m√©todos necess√°rios para implementar: `preprocess`,
`_forward`, `postprocess` and `_sanitize_parameters`.



```python
from transformers import Pipeline


class MyPipeline(Pipeline):
    def _sanitize_parameters(self, **kwargs):
        preprocess_kwargs = {}
        if "maybe_arg" in kwargs:
            preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]
        return preprocess_kwargs, {}, {}

    def preprocess(self, inputs, maybe_arg=2):
        model_input = Tensor(inputs["input_ids"])
        return {"model_input": model_input}

    def _forward(self, model_inputs):
        # model_inputs == {"model_input": model_input}
        outputs = self.model(**model_inputs)
        # Maybe {"logits": Tensor(...)}
        return outputs

    def postprocess(self, model_outputs):
        best_class = model_outputs["logits"].softmax(-1)
        return best_class
```
A estrutura dividida √© intencional e feita para facilitar o suporte √† CPU/GPU, ao mesmo tempo que possibilita a execu√ß√£o etapas do pr√©/p√≥s processamentos em diferentes threads na CPU.

`preprocess` originalmente receber√° os inputs definidos, e os pr√©-processar√° de maneira adequada para realizar a infer√™ncia no modelo, que pode conter mais informa√ß√µes e geralmente √© um `Dict`.

`_forward` √© um detalhe de implementa√ß√£o e n√£o deve ser usado diretamente. `forward` √© o m√©todo que dever√° ser chamado, j√° que cont√©m prote√ß√µes para garantir que tudo rode no mesmo dispositivo. Se algo estiver realmente ligado ao modelo, ent√£o pertencer√° ao m√©todo `_forward`, qualquer coisa extra pertencer√° √† preprocess/postprocess.

`postprocess` receber√° as sa√≠das de  `_forward` e as transformar√° no sa√≠da final definida anteriormente. 

`_sanitize_parameters` existe para permitir o usu√°rio passar quaisquer par√¢metros que quiser, sejam esses chamados durante a inicializa√ß√£o `pipeline(...., maybe_arg=4)` ou durante a chamada da classe `pipe = pipeline(...); output = pipe(...., maybe_arg=4)`.

O retorno do m√©todo `_sanitize_parameters` s√£o 3 dicion√°rios de kwargs que ser√£o passados diretamente para `preprocess`, `_forward` e `postprocess`. N√£o preencha nada que o **caller** n√£o chame sem um par√¢metro extra. Isso permite manter os par√¢metros padr√£o  na defini√ß√£o do m√©todo, o que √© sempre mais "natural". 

Um exemplo cl√°ssico seria a adi√ß√£o de um par√¢metro `top_k` no p√≥s processamento em tasks de classifica√ß√£o.

```python
>>> pipe = pipeline("my-new-task")
>>> pipe("This is a test")
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}, {"label": "3-star", "score": 0.05}
{"label": "4-star", "score": 0.025}, {"label": "5-star", "score": 0.025}]

>>> pipe("This is a test", top_k=2)
[{"label": "1-star", "score": 0.8}, {"label": "2-star", "score": 0.1}]
```

Para implement√°-la, atualizaremos o m√©todo `postprocess` com um par√¢metro de valor padr√£o `5`. e editar o m√©todo `_sanitize_parameters` para permitir esse novo par√¢metro.


```python
def postprocess(self, model_outputs, top_k=5):
    best_class = model_outputs["logits"].softmax(-1)
    # Add logic to handle top_k
    return best_class


def _sanitize_parameters(self, **kwargs):
    preprocess_kwargs = {}
    if "maybe_arg" in kwargs:
        preprocess_kwargs["maybe_arg"] = kwargs["maybe_arg"]

    postprocess_kwargs = {}
    if "top_k" in kwargs:
        preprocess_kwargs["top_k"] = kwargs["top_k"]
    return preprocess_kwargs, {}, postprocess_kwargs
```

Tente manter os inputs/outputs simples e idealmente JSON-serializ√°vel, pois isso torna o uso da pipeline extramemente f√°cil por n√£o requerir que usu√°rios entendam novos tipos de objetos. √â relativamente comum suportar diferentes tipos de argumentos para facilitar o uso (arquivos de √°udio, nome de arquivos, URLS ou bytes puros)

## Adicionando a pipeline √† lista de tasks suportadas

V√° at√© `src/transformers/pipelines/__init__.py` e preencha `SUPPORTED_TASKS` com sua rec√©m criada pipeline.
Se poss√≠vel, essa deve definir um modelo padr√£o.

## Adicionando testes

Crie um novo arquivo `tests/test_pipelines_MY_PIPELINE.py` tendo como exemplo os outros testes.

O m√©todo `run_pipeline_test` √© gen√©rico e rodar√° em modelos pequenos aleat√≥rios de todas possiveis arquiteturas espec√≠ficadas em `model_mapping` e `tf_model_mapping`.

Essa etapa √© importante para testar a compatibilidade no futuro, o que significa que se alguem adicionar um novo modelo para `XXXForQuestionAnswering`, ent√£o os testes da pipeline v√£o tentar rodar os testes nesse novo modelo adicionado. Porque os modelos s√£o aleat√≥riamente selecionados √© impossivel checar valores reais. Por isso existe um helper `ANY` que simplesmente checar√° se a sa√≠da da pipeline coincide com o tipo de pipeline espec√≠ficado. 

Voc√™ tamb√©m *deve* implementar 2 (idealmente 4) testes.

- `test_small_model_pt` : Defina 1 modelo "small" para essa pipeline (N√£o importa se os resultados n√£o fizerem sentido) e teste as sa√≠das da pipeline. Os resultados devem ser iguais aos de `test_small_model_tf`.
- `test_small_model_tf` : Define 1 modelo "small" para essa pipeline (N√£o importa se os resultados n√£o fizerem sentido) e teste as sa√≠das da pipeline.  Os resultados devem ser iguais aos de `test_small_model_pt`.
- `test_large_model_pt` (`optional`): Testa a pipeline em uma pipeline real, onde os resultados supostamente devem fazer sentido. Esses testes s√£o lentos e devem ser marcados como. Aqui o objetivo √© exibir a pipeline e garantir que n√£o h√° "drift" em releases futuras.
- `test_large_model_tf` (`optional`): Testa a pipeline em uma pipeline real, onde os resultados supostamente devem fazer sentido. Esses testes s√£o lentos e devem ser marcados como. Aqui o objetivo √© exibir a pipeline e garantir que n√£o h√° "drift" em releases futuras.